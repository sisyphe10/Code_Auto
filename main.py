import time
import schedule
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import os
import csv
import yfinance as yf
import warnings
from pykrx import stock

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.simplefilter(action='ignore', category=FutureWarning)

# === ìƒìˆ˜ ì •ì˜ ===
CSV_FILE = 'dataset.csv'

# DRAM ì œí’ˆëª…
TARGET_DRAM_ITEMS = {
    'DDR5 16G (2Gx8) 4800/5600': 'DDR5 16G (2Gx8) 4800/5600',
    'DDR4 16Gb (1Gx16)3200': 'DDR4 16Gb (1Gx16)3200',
    'DDR4 16Gb (2Gx8)3200': 'DDR4 16Gb (2Gx8)3200',
    'DDR4 8Gb (1Gx8) 3200': 'DDR4 8Gb (1Gx8) 3200',
    'DDR4 8Gb (512Mx16) 3200': 'DDR4 8Gb (512Mx16) 3200'
}

# NAND ì œí’ˆëª…
TARGET_NAND_ITEMS = {
    'SLC 2Gb 256MBx8': 'SLC 2Gb 256MBx8',
    'SLC 1Gb 128MBx8': 'SLC 1Gb 128MBx8',
    'MLC 64Gb 8GBx8': 'MLC 64Gb 8GBx8',
    'MLC 32Gb 4GBx8': 'MLC 32Gb 4GBx8'
}

# yfinance í‹°ì»¤ ëª©ë¡ (ì§€ìˆ˜ëŠ” ë³„ë„ í•¨ìˆ˜ë¡œ ëºìŒ)
# yfinance í‹°ì»¤ ëª©ë¡ (í™˜ìœ¨ ì¶”ê°€ë¨)
# yfinance í‹°ì»¤ ëª©ë¡
YFINANCE_TICKERS = {
    # --- ì•”í˜¸í™”í ---
    'Bitcoin': {'ticker': 'BTC-USD', 'type': 'CRYPTO'},
    'Ethereum': {'ticker': 'ETH-USD', 'type': 'CRYPTO'},
    'Binance Coin': {'ticker': 'BNB-USD', 'type': 'CRYPTO'},

    # --- ì›ìì¬ ---
    'WTI Crude Oil': {'ticker': 'CL=F', 'type': 'COMMODITY'},
    'Brent Crude Oil': {'ticker': 'BZ=F', 'type': 'COMMODITY'},
    'Natural Gas': {'ticker': 'NG=F', 'type': 'COMMODITY'},
    'Gold': {'ticker': 'GC=F', 'type': 'COMMODITY'},
    'Silver': {'ticker': 'SI=F', 'type': 'COMMODITY'},
    'Copper': {'ticker': 'HG=F', 'type': 'COMMODITY'},
    'Uranium ETF (URA)': {'ticker': 'URA', 'type': 'COMMODITY'},

    # --- ì§€ìˆ˜ ë° ê¸ˆë¦¬ ---
    'VIX Index': {'ticker': '^VIX', 'type': 'INDEX'},
    'US 10 Year Treasury Yield': {'ticker': '^TNX', 'type': 'INTEREST_RATE'},

    # --- í™˜ìœ¨ (FX) ---
    # ì´ì œ ëª¨ë“  í™˜ìœ¨ì´ "1ë‹¬ëŸ¬ë‹¹ ì–¼ë§ˆ" ê¸°ì¤€ìœ¼ë¡œ í†µì¼ë©ë‹ˆë‹¤.
    'Dollar Index (DXY)': {'ticker': 'DX-Y.NYB', 'type': 'FX'},
    'KRW/USD': {'ticker': 'KRW=X', 'type': 'FX'},  # ì›/ë‹¬ëŸ¬ (ì˜ˆ: 1450)
    'JPY/USD': {'ticker': 'JPY=X', 'type': 'FX'},  # ì—”/ë‹¬ëŸ¬ (ì˜ˆ: 150)
    'CNY/USD': {'ticker': 'CNY=X', 'type': 'FX'},  # ìœ„ì•ˆ/ë‹¬ëŸ¬ (ì˜ˆ: 7.2)
    'TWD/USD': {'ticker': 'TWD=X', 'type': 'FX'},  # ëŒ€ë§Œë‹¬ëŸ¬/ë‹¬ëŸ¬ (ì˜ˆ: 32.5)

    # [ë³€ê²½] EUR=Xë¥¼ ì“°ë©´ '1ë‹¬ëŸ¬ë‹¹ ìœ ë¡œ'ê°€ ë‚˜ì˜µë‹ˆë‹¤.
    'EUR/USD': {'ticker': 'EUR=X', 'type': 'FX'},  # ìœ ë¡œ/ë‹¬ëŸ¬ (ì˜ˆ: 0.96)
}


# === ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ===
def setup_csv():
    """CSV íŒŒì¼ ì´ˆê¸° ì„¤ì •"""
    if not os.path.exists(CSV_FILE):
        with open(CSV_FILE, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(['ë‚ ì§œ', 'ì œí’ˆëª…', 'ê°€ê²©', 'ë°ì´í„° íƒ€ì…'])
        print(f"âœ… CSV íŒŒì¼ ìƒì„± ì™„ë£Œ: {CSV_FILE}")
    else:
        print(f"âœ… ê¸°ì¡´ CSV íŒŒì¼ ì‚¬ìš©: {CSV_FILE}")


def setup_driver(headless=True):
    """Selenium ì›¹ë“œë¼ì´ë²„ ì„¤ì •"""
    chrome_options = Options()
    if headless:
        chrome_options.add_argument('--headless')

    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    chrome_options.add_argument('--user-agent=Mozilla/5.0')

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver


def save_to_csv(data):
    """ì¤‘ë³µ ë°©ì§€ ê¸°ëŠ¥ì´ ê°•í™”ëœ CSV ì €ì¥ (ë°°ì¹˜ ë‚´ ì¤‘ë³µê¹Œì§€ ì œê±°)"""
    try:
        # 1. íŒŒì¼ì— ì´ë¯¸ ì €ì¥ëœ ë°ì´í„° í‚¤ ë¡œë“œ
        existing_keys = set()
        if os.path.exists(CSV_FILE):
            with open(CSV_FILE, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f)
                next(reader, None)
                for row in reader:
                    if len(row) >= 2:
                        key = (row[0], row[1])
                        existing_keys.add(key)

        new_data = []
        # [í•µì‹¬ ìˆ˜ì •] ì´ë²ˆì— ì €ì¥í•  ë°ì´í„°ë¼ë¦¬ì˜ ì¤‘ë³µë„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì„¸íŠ¸
        current_batch_keys = set()

        for row in data:
            current_key = (row[0], row[1])

            # 1) íŒŒì¼ì— ì—†ê³   AND  2) ì§€ê¸ˆ ì €ì¥í•˜ë ¤ëŠ” ë¦¬ìŠ¤íŠ¸ì—ë„ ì—†ì„ ë•Œë§Œ ì¶”ê°€
            if current_key not in existing_keys and current_key not in current_batch_keys:
                new_data.append(row)
                current_batch_keys.add(current_key)  # ë°©ê¸ˆ ì¶”ê°€í–ˆìŒì„ ê¸°ë¡

        if new_data:
            with open(CSV_FILE, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                for row in new_data:
                    writer.writerow(row)
            print(f"âœ… {len(new_data)}ê±´ ì €ì¥ ì™„ë£Œ (ì¤‘ë³µ ì œì™¸ë¨)")
            return True
        else:
            print("ğŸ’¡ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë‘ ì¤‘ë³µ)")
            return True

    except Exception as e:
        print(f"\nâŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False


def get_last_scfi_date():
    try:
        if not os.path.exists(CSV_FILE): return None
        last_date = None
        with open(CSV_FILE, 'r', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            next(reader, None)
            for row in reader:
                if len(row) >= 4 and row[3] == 'OCEAN_FREIGHT' and 'SCFI' in row[1]:
                    last_date = row[0]
        return last_date
    except:
        return None


# ==========================================
# 1. [KRX] í•œêµ­ ì§€ìˆ˜/ì‹œì´/PER/PBR
# ==========================================
def crawl_krx_indices():
    """
    KOSPI, KOSDAQ, KOSPI200ì˜ ì§€ìˆ˜, ì‹œê°€ì´ì•¡, PER, PBR, [ì¶”ê°€] ìˆœìˆ˜ ì¢…ëª©ìˆ˜ ìˆ˜ì§‘
    """
    print(f"\n{'=' * 60}")
    print(f"ğŸ‡°ğŸ‡· KRX ì¢…í•© ë°ì´í„°(ì¢…ëª©ìˆ˜ í¬í•¨) í¬ë¡¤ë§ ì‹œì‘")
    print(f"{'=' * 60}")

    target_date = datetime.now()
    valid_date_str = None

    for i in range(7):
        check_date = (target_date - timedelta(days=i)).strftime("%Y%m%d")
        try:
            test_df = stock.get_index_ohlcv_by_date(check_date, check_date, "1001")
            if not test_df.empty:
                valid_date_str = check_date
                break
        except:
            continue

    if not valid_date_str:
        print("âŒ ìœ íš¨í•œ KRX ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    default_date = datetime.strptime(valid_date_str, "%Y%m%d").strftime("%Y-%m-%d")
    print(f"ğŸ“… ì¡°íšŒ ê¸°ì¤€ì¼: {default_date}")

    targets = {"KOSPI": "KOSPI", "KOSDAQ": "KOSDAQ", "KOSPI 200": "KOSPI"}
    # ì£¼ì˜: KOSPI 200ì€ ì§€ìˆ˜ì§€ë§Œ ì¢…ëª©ìˆ˜ëŠ” KOSPI ì‹œì¥ ì „ì²´ë¥¼ ì„¸ëŠ”ê²Œ ë§ëŠ”ì§€,
    # í˜¹ì€ êµ¬ì„±ì¢…ëª©(200ê°œ)ì„ ì„¸ëŠ”ê²Œ ë§ëŠ”ì§€ ì• ë§¤í•˜ì§€ë§Œ, ë³´í†µ ì‹œì¥ ì „ì²´(KOSPI/KOSDAQ) ì¢…ëª©ìˆ˜ë¥¼ ë´…ë‹ˆë‹¤.
    # ì—¬ê¸°ì„œëŠ” KOSPI, KOSDAQ ë‘ ì‹œì¥ì˜ ì¢…ëª©ìˆ˜ë§Œ ì§‘ê³„í•˜ê² ìŠµë‹ˆë‹¤.

    collected_data = []
    start_lookup = (datetime.strptime(valid_date_str, "%Y%m%d") - timedelta(days=5)).strftime("%Y%m%d")

    # 1. [ì‹ ê·œ] ìˆœìˆ˜ ìƒì¥ ì¢…ëª©ìˆ˜ ì¹´ìš´íŠ¸ (KOSPI, KOSDAQ)
    market_map = {"KOSPI": "KOSPI", "KOSDAQ": "KOSDAQ"}

    for market_name, market_code in market_map.items():
        try:
            # í•´ë‹¹ ì‹œì¥ì˜ ì „ì²´ í‹°ì»¤ ê°€ì ¸ì˜¤ê¸° (ETF, ETNì€ ê¸°ë³¸ ì œì™¸ë¨)
            tickers = stock.get_market_ticker_list(valid_date_str, market=market_code)

            real_stock_count = 0
            for ticker in tickers:
                # í•„í„°ë§ ë¡œì§
                # 1. í‹°ì»¤ ëìë¦¬ í™•ì¸: ë³´í†µì£¼ëŠ” '0'ìœ¼ë¡œ ëë‚¨ (ìš°ì„ ì£¼ ë“± ì œì™¸)
                if ticker[-1] != '0':
                    continue

                # 2. ì´ë¦„ìœ¼ë¡œ ìŠ¤íŒ©/ë¦¬ì¸  ê±°ë¥´ê¸° (í™•ì‹¤íˆ í•˜ê¸° ìœ„í•´ ì´ë¦„ ì¡°íšŒ)
                name = stock.get_market_ticker_name(ticker)
                if 'ìŠ¤íŒ©' in name or 'ë¦¬ì¸ ' in name:
                    continue

                real_stock_count += 1

            collected_data.append((default_date, f"{market_name} ìƒì¥ì¢…ëª©ìˆ˜", real_stock_count, 'INDEX_KR'))
            print(f"âœ“ {market_name} ìˆœìˆ˜ ì¢…ëª©ìˆ˜: {real_stock_count}ê°œ")

        except Exception as e:
            print(f"âŒ {market_name} ì¢…ëª©ìˆ˜ ì§‘ê³„ ì‹¤íŒ¨: {e}")

    # 2. ê¸°ì¡´ ì§€ìˆ˜/ì‹œì´/PER/PBR ë¡œì§
    # (í‹°ì»¤ ë§¤í•‘ìš©)
    index_targets = {"KOSPI": "1001", "KOSDAQ": "2001", "KOSPI 200": "1028"}

    for name, ticker in index_targets.items():
        try:
            # A. ì§€ìˆ˜/ì‹œì´
            df_price = stock.get_index_ohlcv_by_date(valid_date_str, valid_date_str, ticker)
            if not df_price.empty:
                price = float(df_price['ì¢…ê°€'].iloc[0])
                collected_data.append((default_date, name, price, 'INDEX_KR'))
                print(f"âœ“ {name}: {price:,.2f}")

                if 'ìƒì¥ì‹œê°€ì´ì•¡' in df_price.columns:
                    market_cap = float(df_price['ìƒì¥ì‹œê°€ì´ì•¡'].iloc[0])
                    collected_data.append((default_date, f"{name} ì‹œê°€ì´ì•¡", market_cap, 'INDEX_KR'))

            # B. PER/PBR
            df_fund = stock.get_index_fundamental_by_date(start_lookup, valid_date_str, ticker)
            if not df_fund.empty:
                if 'PER' in df_fund.columns:
                    valid = df_fund[df_fund['PER'] > 0]
                    if not valid.empty:
                        val = float(valid.iloc[-1]['PER'])
                        r_date = valid.iloc[-1].name.strftime("%Y-%m-%d")
                        collected_data.append((r_date, f"{name} PER", val, 'INDEX_KR'))
                        print(f"  -> PER: {val} ({r_date})")

                if 'PBR' in df_fund.columns:
                    valid = df_fund[df_fund['PBR'] > 0]
                    if not valid.empty:
                        val = float(valid.iloc[-1]['PBR'])
                        r_date = valid.iloc[-1].name.strftime("%Y-%m-%d")
                        collected_data.append((r_date, f"{name} PBR", val, 'INDEX_KR'))

        except Exception as e:
            print(f"âŒ {name} ì§€ìˆ˜ ë°ì´í„° ì˜¤ë¥˜: {e}")

    if collected_data:
        save_to_csv(collected_data)
        return True
    return False


# ==========================================
# 2. [US] ë¯¸êµ­ ì§€ìˆ˜/PER/PBR (ETF ëŒ€ìš©)
# ==========================================
def crawl_us_indices():
    """ë¯¸êµ­ ì§€ìˆ˜ëŠ” Indexë¡œ ê°€ê²©ì„, ëŒ€í˜• ETFë¡œ í€ë”ë©˜íƒˆ(PER/PBR)ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    print(f"\n{'=' * 60}")
    print(f"ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì§€ìˆ˜/PER/PBR í¬ë¡¤ë§ ì‹œì‘ (yfinance)")
    print(f"{'=' * 60}")

    current_date = datetime.now().strftime('%Y-%m-%d')

    # ì§€ìˆ˜ í‹°ì»¤(ê°€ê²©ìš©) / ETF í‹°ì»¤(í€ë”ë©˜íƒˆìš©) ë§¤í•‘
    targets = {
        "S&P 500": {"idx": "^GSPC", "etf": "SPY"},
        "NASDAQ": {"idx": "^IXIC", "etf": "QQQ"},  # NASDAQ 100 ê¸°ì¤€
        "RUSSELL 2000": {"idx": "^RUT", "etf": "IWM"}
    }

    collected_data = []

    for name, tickers in targets.items():
        try:
            # 1. ì§€ìˆ˜ ê°€ê²© (Index Ticker)
            idx_ticker = yf.Ticker(tickers['idx'])
            hist = idx_ticker.history(period="1d")

            if not hist.empty:
                price = float(hist['Close'].iloc[0])
                d_date = hist.index[0].strftime('%Y-%m-%d')  # ì‹¤ì œ ì¥ ë§ˆê°ì¼
                collected_data.append((d_date, name, price, 'INDEX_US'))
                print(f"âœ“ {name}: {price:,.2f}")

                # 2. í€ë”ë©˜íƒˆ (ETF Ticker)
                # ì§€ìˆ˜ ìì²´ëŠ” PER/PBR ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ê°€ ë§ì•„ ETFë¥¼ Proxyë¡œ ì‚¬ìš©
                etf_ticker = yf.Ticker(tickers['etf'])
                info = etf_ticker.info

                # PER
                if 'trailingPE' in info and info['trailingPE']:
                    pe = info['trailingPE']
                    collected_data.append((d_date, f"{name} PER", pe, 'INDEX_US'))
                    print(f"  -> PER: {pe:.2f}")

                # PBR
                if 'priceToBook' in info and info['priceToBook']:
                    pbr = info['priceToBook']
                    collected_data.append((d_date, f"{name} PBR", pbr, 'INDEX_US'))
                    print(f"  -> PBR: {pbr:.2f}")

                # ì‹œê°€ì´ì•¡ (ì£¼ì˜: ETF ì‹œì´ì´ ì•„ë‹ˆë¼ ì „ì²´ ì§€ìˆ˜ ì‹œì´ì€ ë¬´ë£Œ APIë¡œ ì–»ê¸° ë§¤ìš° í˜ë“­ë‹ˆë‹¤)
                # yfinance Index tickerì˜ infoì— marketCapì´ ìˆëŠ” ê²½ìš°ë§Œ ìˆ˜ì§‘
                # (ë³´í†µ S&P500 ê°™ì€ ì§€ìˆ˜ëŠ” marketCapì´ Noneìœ¼ë¡œ ë‚˜ì˜µë‹ˆë‹¤)
                if 'marketCap' in idx_ticker.info and idx_ticker.info['marketCap']:
                    mkt_cap = idx_ticker.info['marketCap']
                    collected_data.append((d_date, f"{name} ì‹œê°€ì´ì•¡", mkt_cap, 'INDEX_US'))

        except Exception as e:
            print(f"âŒ {name} ì˜¤ë¥˜: {e}")

    if collected_data:
        save_to_csv(collected_data)


def crawl_dram_nand(data_type):
    """DRAM ë° NAND ê°€ê²© í¬ë¡¤ë§ (ì¤‘ë³µ ìˆ˜ì§‘ ë°©ì§€ ì ìš©)"""
    print(f"\nğŸ“Š {data_type} í¬ë¡¤ë§ ì‹œì‘")
    driver = None
    try:
        driver = setup_driver()
        driver.get(f'https://www.dramexchange.com/#{data_type.lower()}')
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'table')))

        current_date = datetime.now().strftime('%Y-%m-%d')
        collected_data = []
        target_items = TARGET_DRAM_ITEMS if data_type == 'DRAM' else TARGET_NAND_ITEMS

        # [í•µì‹¬ ìˆ˜ì •] ì´ë¯¸ ì°¾ì€ ì œí’ˆëª…ì„ ê¸°ì–µí•˜ëŠ” ì„¸íŠ¸
        found_items = set()

        tables = driver.find_elements(By.TAG_NAME, 'table')
        for table in tables:
            rows = table.find_elements(By.TAG_NAME, 'tr')
            for row in rows:
                cells = row.find_elements(By.TAG_NAME, 'td')
                if not cells: cells = row.find_elements(By.TAG_NAME, 'th')
                if len(cells) < 2: continue

                item_name = cells[0].text.strip()

                # íƒ€ê²Ÿ ì œí’ˆì´ë©´ì„œ + ì•„ì§ ìˆ˜ì§‘í•˜ì§€ ì•Šì€ ì œí’ˆì¸ ê²½ìš°ì—ë§Œ!
                if item_name in target_items and item_name not in found_items:
                    try:
                        price = cells[1].text.strip()
                        if price and price.replace('.', '').replace(',', '').isdigit():
                            val = float(price.replace(',', ''))
                            collected_data.append((current_date, item_name, val, data_type))
                            found_items.add(item_name)  # "ë‚˜ ì´ê±° ì°¾ì•˜ìŒ" ê¸°ë¡
                            print(f"âœ“ {item_name}: ${price}")
                    except:
                        pass

        if collected_data:
            save_to_csv(collected_data)
        else:
            print(f"âš ï¸ {data_type} ë°ì´í„° ì—†ìŒ")

    except Exception as e:
        print(f"âŒ {data_type} ì˜¤ë¥˜: {e}")
    finally:
        if driver: driver.quit()


def crawl_scfi_index():
    print(f"\nğŸš¢ SCFI í¬ë¡¤ë§ ì‹œì‘")
    driver = None
    try:
        driver = setup_driver()
        driver.get('https://en.sse.net.cn/indices/scfinew.jsp')
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'currdate')))

        scfi_date = driver.find_element(By.ID, 'currdate').text.strip()
        scfi_value = None

        tables = driver.find_elements(By.TAG_NAME, 'table')
        for table in tables:
            if 'Comprehensive Index' in table.text:
                rows = table.find_elements(By.TAG_NAME, 'tr')
                for row in rows:
                    if 'Comprehensive Index' in row.text:
                        idx4 = row.find_elements(By.CSS_SELECTOR, 'span.idx4')
                        if idx4: scfi_value = idx4[0].text.strip()

        if scfi_value and scfi_date:
            if get_last_scfi_date() == scfi_date:
                print(f"ğŸ’¡ SCFI ìµœì‹  ìƒíƒœ ({scfi_date})")
            else:
                save_to_csv([(scfi_date, 'SCFI Comprehensive Index', float(scfi_value), 'OCEAN_FREIGHT')])
                print(f"âœ… SCFI ì €ì¥: {scfi_value}")
    except Exception as e:
        print(f"âŒ SCFI ì˜¤ë¥˜: {e}")
    finally:
        if driver: driver.quit()


def crawl_yfinance_data():
    print(f"\nğŸ“ˆ yfinance í¬ë¡¤ë§ ì‹œì‘")
    current_date = datetime.now().strftime('%Y-%m-%d')
    collected_data = []
    for name, info in YFINANCE_TICKERS.items():
        try:
            t = yf.Ticker(info['ticker'])
            h = t.history(period='1d')
            if not h.empty:
                price = float(h['Close'].iloc[0])
                d = h.index[0].strftime('%Y-%m-%d') if info['type'] != 'CRYPTO' else current_date
                collected_data.append((d, name, price, info['type']))
                print(f"âœ“ {name}: {price:.2f}")
        except:
            print(f"âš ï¸ {name} ì‹¤íŒ¨")

    if collected_data: save_to_csv(collected_data)


def main():
    print("ğŸš€ ì „ì²´ í¬ë¡¤ë§ ì‹œì‘")
    setup_csv()

    crawl_dram_nand('DRAM')
    crawl_dram_nand('NAND')
    crawl_scfi_index()
    crawl_yfinance_data()

    # í•œêµ­ ì§€ìˆ˜
    crawl_krx_indices()
    # ë¯¸êµ­ ì§€ìˆ˜
    crawl_us_indices()

    print(f"\nğŸ“ ê²°ê³¼ íŒŒì¼: {CSV_FILE}")


if __name__ == "__main__":
    main()
