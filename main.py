import time
import schedule
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import os
import csv
import yfinance as yf
import warnings
from pykrx import stock

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.simplefilter(action='ignore', category=FutureWarning)

# === ìƒìˆ˜ ì •ì˜ ===
CSV_FILE = 'dataset.csv'

# DRAM ì œí’ˆëª…
TARGET_DRAM_ITEMS = {
    'DDR5 16G (2Gx8) 4800/5600': 'DDR5 16G (2Gx8) 4800/5600',
    'DDR4 16Gb (1Gx16)3200': 'DDR4 16Gb (1Gx16)3200',
    'DDR4 16Gb (2Gx8)3200': 'DDR4 16Gb (2Gx8)3200',
    'DDR4 8Gb (1Gx8) 3200': 'DDR4 8Gb (1Gx8) 3200',
    'DDR4 8Gb (512Mx16) 3200': 'DDR4 8Gb (512Mx16) 3200'
}

# NAND ì œí’ˆëª…
TARGET_NAND_ITEMS = {
    'SLC 2Gb 256MBx8': 'SLC 2Gb 256MBx8',
    'SLC 1Gb 128MBx8': 'SLC 1Gb 128MBx8',
    'MLC 64Gb 8GBx8': 'MLC 64Gb 8GBx8',
    'MLC 32Gb 4GBx8': 'MLC 32Gb 4GBx8'
}

# yfinance í‹°ì»¤ ëª©ë¡ (ì§€ìˆ˜ëŠ” ë³„ë„ í•¨ìˆ˜ë¡œ ëºìŒ)
YFINANCE_TICKERS = {
    'Bitcoin': {'ticker': 'BTC-USD', 'type': 'CRYPTO'},
    'Ethereum': {'ticker': 'ETH-USD', 'type': 'CRYPTO'},
    'Binance Coin': {'ticker': 'BNB-USD', 'type': 'CRYPTO'},
    'WTI Crude Oil': {'ticker': 'CL=F', 'type': 'COMMODITY'},
    'Brent Crude Oil': {'ticker': 'BZ=F', 'type': 'COMMODITY'},
    'Natural Gas': {'ticker': 'NG=F', 'type': 'COMMODITY'},
    'Gold': {'ticker': 'GC=F', 'type': 'COMMODITY'},
    'Silver': {'ticker': 'SI=F', 'type': 'COMMODITY'},
    'Copper': {'ticker': 'HG=F', 'type': 'COMMODITY'},
    'Uranium ETF (URA)': {'ticker': 'URA', 'type': 'COMMODITY'},
    'VIX Index': {'ticker': '^VIX', 'type': 'INDEX'},
    'Dollar Index (DXY)': {'ticker': 'DX-Y.NYB', 'type': 'FX'},
    'KRW/USD': {'ticker': 'KRW=X', 'type': 'FX'},
    'JPY/USD': {'ticker': 'JPY=X', 'type': 'FX'},
    'US 10 Year Treasury Yield': {'ticker': '^TNX', 'type': 'INTEREST_RATE'}
}


# === ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ===
def setup_csv():
    """CSV íŒŒì¼ ì´ˆê¸° ì„¤ì •"""
    if not os.path.exists(CSV_FILE):
        with open(CSV_FILE, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(['ë‚ ì§œ', 'ì œí’ˆëª…', 'ê°€ê²©', 'ë°ì´í„° íƒ€ì…'])
        print(f"âœ… CSV íŒŒì¼ ìƒì„± ì™„ë£Œ: {CSV_FILE}")
    else:
        print(f"âœ… ê¸°ì¡´ CSV íŒŒì¼ ì‚¬ìš©: {CSV_FILE}")


def setup_driver(headless=True):
    """Selenium ì›¹ë“œë¼ì´ë²„ ì„¤ì •"""
    chrome_options = Options()
    if headless:
        chrome_options.add_argument('--headless')

    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    chrome_options.add_argument('--user-agent=Mozilla/5.0')

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver


def save_to_csv(data):
    """ì¤‘ë³µ ë°©ì§€ ê¸°ëŠ¥ì´ ì¶”ê°€ëœ CSV ì €ì¥"""
    try:
        existing_keys = set()
        if os.path.exists(CSV_FILE):
            with open(CSV_FILE, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f)
                next(reader, None)
                for row in reader:
                    if len(row) >= 2:
                        key = (row[0], row[1])
                        existing_keys.add(key)

        new_data = []
        for row in data:
            current_key = (row[0], row[1])
            if current_key not in existing_keys:
                new_data.append(row)

        if new_data:
            with open(CSV_FILE, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                for row in new_data:
                    writer.writerow(row)
            print(f"âœ… {len(new_data)}ê±´ ì €ì¥ ì™„ë£Œ (ì¤‘ë³µ ì œì™¸ë¨)")
            return True
        else:
            print("ğŸ’¡ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë‘ ì¤‘ë³µ)")
            return True

    except Exception as e:
        print(f"\nâŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False


def get_last_scfi_date():
    try:
        if not os.path.exists(CSV_FILE): return None
        last_date = None
        with open(CSV_FILE, 'r', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            next(reader, None)
            for row in reader:
                if len(row) >= 4 and row[3] == 'OCEAN_FREIGHT' and 'SCFI' in row[1]:
                    last_date = row[0]
        return last_date
    except:
        return None


# ==========================================
# 1. [KRX] í•œêµ­ ì§€ìˆ˜/ì‹œì´/PER/PBR
# ==========================================
def crawl_krx_indices():
    print(f"\n{'=' * 60}")
    print(f"ğŸ‡°ğŸ‡· KRX ì§€ìˆ˜/ì‹œì´/PER/PBR í¬ë¡¤ë§ ì‹œì‘")
    print(f"{'=' * 60}")

    target_date = datetime.now()
    valid_date_str = None

    for i in range(7):
        check_date = (target_date - timedelta(days=i)).strftime("%Y%m%d")
        try:
            test_df = stock.get_index_ohlcv_by_date(check_date, check_date, "1001")
            if not test_df.empty:
                valid_date_str = check_date
                break
        except:
            continue

    if not valid_date_str:
        print("âŒ ìœ íš¨í•œ KRX ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    default_date = datetime.strptime(valid_date_str, "%Y%m%d").strftime("%Y-%m-%d")
    print(f"ğŸ“… ì¡°íšŒ ê¸°ì¤€ì¼: {default_date}")

    targets = {"KOSPI": "1001", "KOSDAQ": "2001", "KOSPI 200": "1028"}
    collected_data = []

    start_lookup = (datetime.strptime(valid_date_str, "%Y%m%d") - timedelta(days=5)).strftime("%Y%m%d")

    for name, ticker in targets.items():
        try:
            # 1. ì§€ìˆ˜ & ì‹œê°€ì´ì•¡
            df_price = stock.get_index_ohlcv_by_date(valid_date_str, valid_date_str, ticker)
            if not df_price.empty:
                price = float(df_price['ì¢…ê°€'].iloc[0])
                collected_data.append((default_date, name, price, 'INDEX_KR'))
                print(f"âœ“ {name}: {price:,.2f}")

                if 'ìƒì¥ì‹œê°€ì´ì•¡' in df_price.columns:
                    market_cap = float(df_price['ìƒì¥ì‹œê°€ì´ì•¡'].iloc[0])
                    collected_data.append((default_date, f"{name} ì‹œê°€ì´ì•¡", market_cap, 'INDEX_KR'))

            # 2. í€ë”ë©˜íƒˆ
            df_fund = stock.get_index_fundamental_by_date(start_lookup, valid_date_str, ticker)
            if not df_fund.empty:
                if 'PER' in df_fund.columns:
                    valid = df_fund[df_fund['PER'] > 0]
                    if not valid.empty:
                        val = float(valid.iloc[-1]['PER'])
                        r_date = valid.iloc[-1].name.strftime("%Y-%m-%d")
                        collected_data.append((r_date, f"{name} PER", val, 'INDEX_KR'))
                        print(f"  -> PER: {val} ({r_date})")

                if 'PBR' in df_fund.columns:
                    valid = df_fund[df_fund['PBR'] > 0]
                    if not valid.empty:
                        val = float(valid.iloc[-1]['PBR'])
                        r_date = valid.iloc[-1].name.strftime("%Y-%m-%d")
                        collected_data.append((r_date, f"{name} PBR", val, 'INDEX_KR'))

        except Exception as e:
            print(f"âŒ {name} ì˜¤ë¥˜: {e}")

    if collected_data:
        save_to_csv(collected_data)


# ==========================================
# 2. [US] ë¯¸êµ­ ì§€ìˆ˜/PER/PBR (ETF ëŒ€ìš©)
# ==========================================
def crawl_us_indices():
    """ë¯¸êµ­ ì§€ìˆ˜ëŠ” Indexë¡œ ê°€ê²©ì„, ëŒ€í˜• ETFë¡œ í€ë”ë©˜íƒˆ(PER/PBR)ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    print(f"\n{'=' * 60}")
    print(f"ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì§€ìˆ˜/PER/PBR í¬ë¡¤ë§ ì‹œì‘ (yfinance)")
    print(f"{'=' * 60}")

    current_date = datetime.now().strftime('%Y-%m-%d')

    # ì§€ìˆ˜ í‹°ì»¤(ê°€ê²©ìš©) / ETF í‹°ì»¤(í€ë”ë©˜íƒˆìš©) ë§¤í•‘
    targets = {
        "S&P 500": {"idx": "^GSPC", "etf": "SPY"},
        "NASDAQ": {"idx": "^IXIC", "etf": "QQQ"},  # NASDAQ 100 ê¸°ì¤€
        "RUSSELL 2000": {"idx": "^RUT", "etf": "IWM"}
    }

    collected_data = []

    for name, tickers in targets.items():
        try:
            # 1. ì§€ìˆ˜ ê°€ê²© (Index Ticker)
            idx_ticker = yf.Ticker(tickers['idx'])
            hist = idx_ticker.history(period="1d")

            if not hist.empty:
                price = float(hist['Close'].iloc[0])
                d_date = hist.index[0].strftime('%Y-%m-%d')  # ì‹¤ì œ ì¥ ë§ˆê°ì¼
                collected_data.append((d_date, name, price, 'INDEX_US'))
                print(f"âœ“ {name}: {price:,.2f}")

                # 2. í€ë”ë©˜íƒˆ (ETF Ticker)
                # ì§€ìˆ˜ ìì²´ëŠ” PER/PBR ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°ê°€ ë§ì•„ ETFë¥¼ Proxyë¡œ ì‚¬ìš©
                etf_ticker = yf.Ticker(tickers['etf'])
                info = etf_ticker.info

                # PER
                if 'trailingPE' in info and info['trailingPE']:
                    pe = info['trailingPE']
                    collected_data.append((d_date, f"{name} PER", pe, 'INDEX_US'))
                    print(f"  -> PER: {pe:.2f}")

                # PBR
                if 'priceToBook' in info and info['priceToBook']:
                    pbr = info['priceToBook']
                    collected_data.append((d_date, f"{name} PBR", pbr, 'INDEX_US'))
                    print(f"  -> PBR: {pbr:.2f}")

                # ì‹œê°€ì´ì•¡ (ì£¼ì˜: ETF ì‹œì´ì´ ì•„ë‹ˆë¼ ì „ì²´ ì§€ìˆ˜ ì‹œì´ì€ ë¬´ë£Œ APIë¡œ ì–»ê¸° ë§¤ìš° í˜ë“­ë‹ˆë‹¤)
                # yfinance Index tickerì˜ infoì— marketCapì´ ìˆëŠ” ê²½ìš°ë§Œ ìˆ˜ì§‘
                # (ë³´í†µ S&P500 ê°™ì€ ì§€ìˆ˜ëŠ” marketCapì´ Noneìœ¼ë¡œ ë‚˜ì˜µë‹ˆë‹¤)
                if 'marketCap' in idx_ticker.info and idx_ticker.info['marketCap']:
                    mkt_cap = idx_ticker.info['marketCap']
                    collected_data.append((d_date, f"{name} ì‹œê°€ì´ì•¡", mkt_cap, 'INDEX_US'))

        except Exception as e:
            print(f"âŒ {name} ì˜¤ë¥˜: {e}")

    if collected_data:
        save_to_csv(collected_data)


# === ê¸°ì¡´ í¬ë¡¤ë§ í•¨ìˆ˜ë“¤ ===
def crawl_dram_nand(data_type):
    print(f"\nğŸ“Š {data_type} í¬ë¡¤ë§ ì‹œì‘")
    driver = None
    try:
        driver = setup_driver()
        driver.get(f'https://www.dramexchange.com/#{data_type.lower()}')
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, 'table')))

        current_date = datetime.now().strftime('%Y-%m-%d')
        collected_data = []
        target_items = TARGET_DRAM_ITEMS if data_type == 'DRAM' else TARGET_NAND_ITEMS

        tables = driver.find_elements(By.TAG_NAME, 'table')
        for table in tables:
            rows = table.find_elements(By.TAG_NAME, 'tr')
            for row in rows:
                cells = row.find_elements(By.TAG_NAME, 'td')
                if len(cells) < 2: continue

                item_name = cells[0].text.strip()
                if item_name in target_items:
                    try:
                        price = cells[1].text.strip()
                        if price and price.replace('.', '').replace(',', '').isdigit():
                            val = float(price.replace(',', ''))
                            collected_data.append((current_date, item_name, val, data_type))
                            print(f"âœ“ {item_name}: ${price}")
                    except:
                        pass

        if collected_data:
            save_to_csv(collected_data)
        else:
            print(f"âš ï¸ {data_type} ë°ì´í„° ì—†ìŒ")

    except Exception as e:
        print(f"âŒ {data_type} ì˜¤ë¥˜: {e}")
    finally:
        if driver: driver.quit()


def crawl_scfi_index():
    print(f"\nğŸš¢ SCFI í¬ë¡¤ë§ ì‹œì‘")
    driver = None
    try:
        driver = setup_driver()
        driver.get('https://en.sse.net.cn/indices/scfinew.jsp')
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'currdate')))

        scfi_date = driver.find_element(By.ID, 'currdate').text.strip()
        scfi_value = None

        tables = driver.find_elements(By.TAG_NAME, 'table')
        for table in tables:
            if 'Comprehensive Index' in table.text:
                rows = table.find_elements(By.TAG_NAME, 'tr')
                for row in rows:
                    if 'Comprehensive Index' in row.text:
                        idx4 = row.find_elements(By.CSS_SELECTOR, 'span.idx4')
                        if idx4: scfi_value = idx4[0].text.strip()

        if scfi_value and scfi_date:
            if get_last_scfi_date() == scfi_date:
                print(f"ğŸ’¡ SCFI ìµœì‹  ìƒíƒœ ({scfi_date})")
            else:
                save_to_csv([(scfi_date, 'SCFI Comprehensive Index', float(scfi_value), 'OCEAN_FREIGHT')])
                print(f"âœ… SCFI ì €ì¥: {scfi_value}")
    except Exception as e:
        print(f"âŒ SCFI ì˜¤ë¥˜: {e}")
    finally:
        if driver: driver.quit()


def crawl_yfinance_data():
    print(f"\nğŸ“ˆ yfinance í¬ë¡¤ë§ ì‹œì‘")
    current_date = datetime.now().strftime('%Y-%m-%d')
    collected_data = []
    for name, info in YFINANCE_TICKERS.items():
        try:
            t = yf.Ticker(info['ticker'])
            h = t.history(period='1d')
            if not h.empty:
                price = float(h['Close'].iloc[0])
                d = h.index[0].strftime('%Y-%m-%d') if info['type'] != 'CRYPTO' else current_date
                collected_data.append((d, name, price, info['type']))
                print(f"âœ“ {name}: {price:.2f}")
        except:
            print(f"âš ï¸ {name} ì‹¤íŒ¨")

    if collected_data: save_to_csv(collected_data)


def main():
    print("ğŸš€ ì „ì²´ í¬ë¡¤ë§ ì‹œì‘")
    setup_csv()

    crawl_dram_nand('DRAM')
    crawl_dram_nand('NAND')
    crawl_scfi_index()
    crawl_yfinance_data()

    # í•œêµ­ ì§€ìˆ˜
    crawl_krx_indices()
    # ë¯¸êµ­ ì§€ìˆ˜
    crawl_us_indices()

    print(f"\nğŸ“ ê²°ê³¼ íŒŒì¼: {CSV_FILE}")


if __name__ == "__main__":
    main()
