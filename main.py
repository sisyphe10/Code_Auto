import time
import schedule
from datetime import datetime, timedelta
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import os
import csv
import yfinance as yf
import warnings
import FinanceDataReader as fdr  # [êµì²´] pykrx ì œê±° ë° fdr ì¶”ê°€
import pandas as pd

# ê²½ê³  ë©”ì‹œì§€ ë¬´ì‹œ
warnings.simplefilter(action='ignore', category=FutureWarning)

# === ìƒìˆ˜ ì •ì˜ ===
CSV_FILE = 'dataset.csv'

# DRAM ì œí’ˆëª…
TARGET_DRAM_ITEMS = {
    'DDR5 16G (2Gx8) 4800/5600': 'DDR5 16G (2Gx8) 4800/5600',
    'DDR4 16Gb (1Gx16)3200': 'DDR4 16Gb (1Gx16)3200',
    'DDR4 16Gb (2Gx8)3200': 'DDR4 16Gb (2Gx8)3200',
    'DDR4 8Gb (1Gx8) 3200': 'DDR4 8Gb (1Gx8) 3200',
    'DDR4 8Gb (512Mx16) 3200': 'DDR4 8Gb (512Mx16) 3200'
}

# NAND ì œí’ˆëª…
TARGET_NAND_ITEMS = {
    'SLC 2Gb 256MBx8': 'SLC 2Gb 256MBx8',
    'SLC 1Gb 128MBx8': 'SLC 1Gb 128MBx8',
    'MLC 64Gb 8GBx8': 'MLC 64Gb 8GBx8',
    'MLC 32Gb 4GBx8': 'MLC 32Gb 4GBx8'
}

# yfinance í‹°ì»¤ ëª©ë¡
YFINANCE_TICKERS = {
    # --- ì•”í˜¸í™”í ---
    'Bitcoin': {'ticker': 'BTC-USD', 'type': 'CRYPTO'},
    'Ethereum': {'ticker': 'ETH-USD', 'type': 'CRYPTO'},
    'Binance Coin': {'ticker': 'BNB-USD', 'type': 'CRYPTO'},

    # --- ì›ìì¬ ---
    'WTI Crude Oil': {'ticker': 'CL=F', 'type': 'COMMODITY'},
    'Brent Crude Oil': {'ticker': 'BZ=F', 'type': 'COMMODITY'},
    'Natural Gas': {'ticker': 'NG=F', 'type': 'COMMODITY'},
    'Gold': {'ticker': 'GC=F', 'type': 'COMMODITY'},
    'Silver': {'ticker': 'SI=F', 'type': 'COMMODITY'},
    'Copper': {'ticker': 'HG=F', 'type': 'COMMODITY'},
    'Uranium ETF (URA)': {'ticker': 'URA', 'type': 'COMMODITY'},

    # --- ì§€ìˆ˜ ë° ê¸ˆë¦¬ ---
    'VIX Index': {'ticker': '^VIX', 'type': 'INDEX'},
    'US 10 Year Treasury Yield': {'ticker': '^TNX', 'type': 'INTEREST_RATE'},

    # --- í™˜ìœ¨ (FX) ---
    'Dollar Index (DXY)': {'ticker': 'DX-Y.NYB', 'type': 'FX'},
    'KRW/USD': {'ticker': 'KRW=X', 'type': 'FX'},
    'JPY/USD': {'ticker': 'JPY=X', 'type': 'FX'},
    'CNY/USD': {'ticker': 'CNY=X', 'type': 'FX'},
    'TWD/USD': {'ticker': 'TWD=X', 'type': 'FX'},
    'EUR/USD': {'ticker': 'EUR=X', 'type': 'FX'},
}


# === ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ===
def setup_csv():
    """CSV íŒŒì¼ ì´ˆê¸° ì„¤ì •"""
    if not os.path.exists(CSV_FILE):
        with open(CSV_FILE, 'w', newline='', encoding='utf-8-sig') as f:
            writer = csv.writer(f)
            writer.writerow(['ë‚ ì§œ', 'ì œí’ˆëª…', 'ê°€ê²©', 'ë°ì´í„° íƒ€ì…'])
        print(f"âœ… CSV íŒŒì¼ ìƒì„± ì™„ë£Œ: {CSV_FILE}")
    else:
        print(f"âœ… ê¸°ì¡´ CSV íŒŒì¼ ì‚¬ìš©: {CSV_FILE}")


def setup_driver(headless=True):
    """Selenium ì›¹ë“œë¼ì´ë²„ ì„¤ì •"""
    chrome_options = Options()
    if headless:
        chrome_options.add_argument('--headless')

    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    chrome_options.add_argument('--user-agent=Mozilla/5.0')

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver


def save_to_csv(data):
    """ì¤‘ë³µ ë°©ì§€ ê¸°ëŠ¥ì´ ê°•í™”ëœ CSV ì €ì¥ (ë°°ì¹˜ ë‚´ ì¤‘ë³µê¹Œì§€ ì œê±°)"""
    try:
        existing_keys = set()
        if os.path.exists(CSV_FILE):
            with open(CSV_FILE, 'r', encoding='utf-8-sig') as f:
                reader = csv.reader(f)
                next(reader, None)
                for row in reader:
                    if len(row) >= 2:
                        key = (row[0], row[1])
                        existing_keys.add(key)

        new_data = []
        current_batch_keys = set()

        for row in data:
            current_key = (row[0], row[1])
            if current_key not in existing_keys and current_key not in current_batch_keys:
                new_data.append(row)
                current_batch_keys.add(current_key)

        if new_data:
            with open(CSV_FILE, 'a', newline='', encoding='utf-8-sig') as f:
                writer = csv.writer(f)
                writer.writerows(new_data)
            print(f"âœ… {len(new_data)}ê±´ ì €ì¥ ì™„ë£Œ (ì¤‘ë³µ ì œì™¸ë¨)")
            return True
        else:
            print("ğŸ’¡ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë‘ ì¤‘ë³µ)")
            return True

    except Exception as e:
        print(f"\nâŒ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False


def get_last_scfi_date():
    try:
        if not os.path.exists(CSV_FILE): return None
        last_date = None
        with open(CSV_FILE, 'r', encoding='utf-8-sig') as f:
            reader = csv.reader(f)
            next(reader, None)
            for row in reader:
                if len(row) >= 4 and row[3] == 'OCEAN_FREIGHT' and 'SCFI' in row[1]:
                    last_date = row[0]
        return last_date
    except:
        return None


# ==========================================
# 1. [KRX] í•œêµ­ ì§€ìˆ˜/ì‹œì´/ì¢…ëª©ìˆ˜ (fdrë¡œ êµì²´)
# ==========================================
def crawl_krx_indices():
    """
    FinanceDataReaderë¥¼ ì‚¬ìš©í•˜ì—¬ KOSPI, KOSDAQì˜ ì§€ìˆ˜, ì‹œê°€ì´ì•¡, ì¢…ëª©ìˆ˜ë¥¼ ìˆ˜ì§‘.
    (ì£¼ì˜: fdrì€ ì§€ìˆ˜ë³„ PER/PBR ë°ì´í„°ë¥¼ ì œê³µí•˜ì§€ ì•Šì•„ í•´ë‹¹ ë¶€ë¶„ì€ ì‚­ì œë¨)
    """
    print(f"\n{'=' * 60}")
    print(f"ğŸ‡°ğŸ‡· KRX ì¢…í•© ë°ì´í„°(fdr) í¬ë¡¤ë§ ì‹œì‘")
    print(f"{'=' * 60}")

    collected_data = []
    # fdrì€ ë³„ë„ ë‚ ì§œ ì§€ì • ì—†ì´ í˜¸ì¶œ ì‹œ ìµœì‹  ë°ì´í„° ìŠ¤ëƒ…ìƒ·ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    today_str = datetime.now().strftime("%Y-%m-%d")

    try:
        # --- 1. ì¢…ëª©ìˆ˜ ë° ì‹œê°€ì´ì•¡ ê³„ì‚° ---
        # KRX ì „ì²´ ìƒì¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        df_master = fdr.StockListing('KRX')
        
        # ì»¬ëŸ¼ëª… ìœ ì—°í™” (MarCap, MarketCap ë“± ë²„ì „ë³„ ì°¨ì´ ëŒ€ì‘)
        col_map = {'MarketCap': 'Marcap', 'MarCap': 'Marcap', 'Name': 'Name', 'Code': 'Code', 'Market': 'Market'}
        df_master = df_master.rename(columns={k: v for k, v in col_map.items() if k in df_master.columns})

        target_markets = ['KOSPI', 'KOSDAQ']
        
        for market in target_markets:
            try:
                # í•´ë‹¹ ì‹œì¥ë§Œ í•„í„°ë§
                mkt_df = df_master[df_master['Market'] == market]
                
                # A. ìˆœìˆ˜ ìƒì¥ ì¢…ëª©ìˆ˜ í•„í„°ë§ (ê¸°ì¡´ ë¡œì§ ìœ ì§€: ìŠ¤íŒ©/ë¦¬ì¸  ì œì™¸, ë³´í†µì£¼ë§Œ)
                # ë³´í†µì£¼: ì¢…ëª©ì½”ë“œê°€ '0'ìœ¼ë¡œ ëë‚¨
                real_stocks = mkt_df[
                    (mkt_df['Code'].str.endswith('0')) & 
                    (~mkt_df['Name'].str.contains('ìŠ¤íŒ©')) & 
                    (~mkt_df['Name'].str.contains('ë¦¬ì¸ '))
                ]
                count = len(real_stocks)
                collected_data.append((today_str, f"{market} ìƒì¥ì¢…ëª©ìˆ˜", count, 'INDEX_KR'))
                print(f"âœ“ {market} ìˆœìˆ˜ ì¢…ëª©ìˆ˜: {count}ê°œ")

                # B. ì‹œê°€ì´ì•¡ í•©ê³„ (ë‹¨ìœ„: ì›)
                if 'Marcap' in mkt_df.columns:
                    total_cap = mkt_df['Marcap'].sum()
                    collected_data.append((today_str, f"{market} ì‹œê°€ì´ì•¡", float(total_cap), 'INDEX_KR'))
                    print(f"âœ“ {market} ì‹œê°€ì´ì•¡ í•©ê³„ ì§‘ê³„ ì™„ë£Œ")

            except Exception as e:
                print(f"âš ï¸ {market} ë¶„ì„ ì‹¤íŒ¨: {e}")

        # --- 2. ì§€ìˆ˜ ê°€ê²© (Index Price) ---
        # ì‹¬ë³¼ ë§¤í•‘: KOSPI -> KS11, KOSDAQ -> KQ11, KOSPI 200 -> KS200
        index_map = {
            'KOSPI': 'KS11',
            'KOSDAQ': 'KQ11',
            'KOSPI 200': 'KS200'
        }

        for name, symbol in index_map.items():
            try:
                # ì˜¤ëŠ˜ ê¸°ì¤€ ìµœê·¼ ë°ì´í„° ì¡°íšŒ (ì£¼ë§/íœ´ì¼ ê³ ë ¤í•˜ì—¬ ìµœê·¼ 5ì¼ì¹˜ ì¤‘ ë§ˆì§€ë§‰ ê°’)
                start_date = (datetime.now() - timedelta(days=5)).strftime("%Y-%m-%d")
                df_idx = fdr.DataReader(symbol, start_date)
                
                if not df_idx.empty:
                    last_row = df_idx.iloc[-1]
                    price = float(last_row['Close'])
                    # ì‹¤ì œ ë°ì´í„° ë‚ ì§œ
                    date_val = last_row.name.strftime("%Y-%m-%d")
                    
                    collected_data.append((date_val, name, price, 'INDEX_KR'))
                    print(f"âœ“ {name} ì§€ìˆ˜: {price:,.2f} ({date_val})")
            except Exception as e:
                print(f"âš ï¸ {name} ì§€ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    except Exception as e:
        print(f"âŒ KRX ë°ì´í„° ìˆ˜ì§‘ ì „ì²´ ì‹¤íŒ¨: {e}")

    if collected_data:
        save_to_csv(collected_data)


# ==========================================
# 2. [US] ë¯¸êµ­ ì§€ìˆ˜/PER/PBR (ETF ëŒ€ìš©)
# ==========================================
def crawl_us_indices():
    """ë¯¸êµ­ ì§€ìˆ˜ëŠ” Indexë¡œ ê°€ê²©ì„, ëŒ€í˜• ETFë¡œ í€ë”ë©˜íƒˆ(PER/PBR)ì„ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    print(f"\n{'=' * 60}")
    print(f"ğŸ‡ºğŸ‡¸ ë¯¸êµ­ ì§€ìˆ˜/PER/PBR í¬ë¡¤ë§ ì‹œì‘ (yfinance)")
    print(f"{'=' * 60}")

    collected_data = []

    targets = {
        "S&P 500": {"idx": "^GSPC", "etf": "SPY"},
        "NASDAQ": {"idx": "^IXIC", "etf": "QQQ"},
        "RUSSELL 2000": {"idx": "^RUT", "etf": "IWM"}
    }

    for name, tickers in
